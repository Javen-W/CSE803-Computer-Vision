{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5765407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import png\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from colormap.colors import Color, hex2rgb\n",
    "from sklearn.metrics import average_precision_score as ap_score\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b5462d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper functions.\n",
    "\"\"\"\n",
    "def save_label(label, path):\n",
    "    '''\n",
    "    Function for ploting labels.\n",
    "    '''\n",
    "    colormap = [\n",
    "        '#000000',\n",
    "        '#0080FF',\n",
    "        '#80FF80',\n",
    "        '#FF8000',\n",
    "        '#FF0000',\n",
    "    ]\n",
    "    assert(np.max(label)<len(colormap))\n",
    "    colors = [hex2rgb(color, normalise=False) for color in colormap]\n",
    "    w = png.Writer(label.shape[1], label.shape[0], palette=colors, bitdepth=4)\n",
    "    with open(path, 'wb') as f:\n",
    "        w.write(f, label)\n",
    "\n",
    "def train(trainloader, net, criterion, optimizer, device, epoch):\n",
    "    '''\n",
    "    Function for training.\n",
    "    '''\n",
    "    start = time.time()\n",
    "    running_loss = 0.0\n",
    "    net = net.train()\n",
    "    for images, labels in tqdm(trainloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss = loss.item()\n",
    "    end = time.time()\n",
    "    print('[epoch %d] loss: %.3f elapsed time %.3f' %\n",
    "          (epoch, running_loss, end-start))\n",
    "\n",
    "def test(testloader, net, criterion, device):\n",
    "    '''\n",
    "    Function for testing.\n",
    "    '''\n",
    "    losses = 0.\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        net = net.eval()\n",
    "        for images, labels in tqdm(testloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = net(images)\n",
    "            loss = criterion(output, labels)\n",
    "            losses += loss.item()\n",
    "            cnt += 1\n",
    "    print(losses / cnt)\n",
    "    return (losses/cnt)\n",
    "\n",
    "def cal_AP(testloader, net, criterion, device):\n",
    "    '''\n",
    "    Calculate Average Precision\n",
    "    '''\n",
    "    losses = 0.\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        net = net.eval()\n",
    "        preds = [[] for _ in range(5)]\n",
    "        heatmaps = [[] for _ in range(5)]\n",
    "        for images, labels in tqdm(testloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = net(images).cpu().numpy()\n",
    "            for c in range(5):\n",
    "                preds[c].append(output[:, c].reshape(-1))\n",
    "                heatmaps[c].append(labels[:, c].cpu().numpy().reshape(-1))\n",
    "\n",
    "        aps = []\n",
    "        for c in range(5):\n",
    "            preds[c] = np.concatenate(preds[c])\n",
    "            heatmaps[c] = np.concatenate(heatmaps[c])\n",
    "            if heatmaps[c].max() == 0:\n",
    "                ap = float('nan')\n",
    "            else:\n",
    "                ap = ap_score(heatmaps[c], preds[c])\n",
    "                aps.append(ap)\n",
    "            print(\"AP = {}\".format(ap))\n",
    "\n",
    "    # print(losses / cnt)\n",
    "    return None\n",
    "\n",
    "def get_result(testloader, net, device, folder='./part3/output_train'):\n",
    "    result = []\n",
    "    cnt = 1\n",
    "    with torch.no_grad():\n",
    "        net = net.eval()\n",
    "        cnt = 0\n",
    "        for images, labels in tqdm(testloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = net(images)[0].cpu().numpy()\n",
    "            c, h, w = output.shape\n",
    "            assert(c == N_CLASS)\n",
    "            y = np.zeros((h,w)).astype('uint8')\n",
    "            for i in range(N_CLASS):\n",
    "                mask = output[i]>0.5\n",
    "                y[mask] = i\n",
    "            gt = labels.cpu().data.numpy().squeeze(0).astype('uint8')\n",
    "            save_label(y, './{}/y{}.png'.format(folder, cnt))\n",
    "            save_label(gt, './{}/gt{}.png'.format(folder, cnt))\n",
    "            plt.imsave(\n",
    "                './{}/x{}.png'.format(folder, cnt),\n",
    "                ((images[0].cpu().data.numpy()+1)*128).astype(np.uint8).transpose(1,2,0))\n",
    "\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9729b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset.\n",
    "\"\"\"\n",
    "class FacadeDataset(Dataset):\n",
    "    def __init__(self, flag, dataDir='./part3/starter_set/', data_range=(0, 8), n_class=5, onehot=False):\n",
    "        self.onehot = onehot\n",
    "        assert(flag in ['train', 'eval', 'test', 'test_dev', 'kaggle'])\n",
    "        print(\"load \"+ flag+\" dataset start\")\n",
    "        print(\"    from: %s\" % dataDir)\n",
    "        print(\"    range: [%d, %d)\" % (data_range[0], data_range[1]))\n",
    "        self.dataset = []\n",
    "        for i in range(data_range[0], data_range[1]):\n",
    "            img = Image.open(os.path.join(dataDir,flag,'eecs442_%04d.jpg' % i))\n",
    "\n",
    "            pngreader = png.Reader(filename=os.path.join(dataDir,flag,'eecs442_%04d.png' % i))\n",
    "            w,h,row,info = pngreader.read()\n",
    "            label = np.array(list(row)).astype('uint8')\n",
    "\n",
    "            # Normalize input image\n",
    "            img = np.asarray(img).astype(\"f\").transpose(2, 0, 1)/128.0-1.0\n",
    "            # Convert to n_class-dimensional onehot matrix\n",
    "            label_ = np.asarray(label)\n",
    "            label = np.zeros((n_class, img.shape[1], img.shape[2])).astype(\"i\")\n",
    "            for j in range(n_class):\n",
    "                label[j, :] = label_ == j\n",
    "            self.dataset.append((img, label))\n",
    "        print(\"load dataset done\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.dataset[index]\n",
    "        label = torch.FloatTensor(label)\n",
    "        if not self.onehot:\n",
    "            label = torch.argmax(label, dim=0)\n",
    "        else:\n",
    "            label = label.long()\n",
    "\n",
    "        return torch.FloatTensor(img), torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62b7bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load train dataset start\n",
      "    from: ./part3/starter_set/\n",
      "    range: [0, 20)\n",
      "load dataset done\n",
      "load test_dev dataset start\n",
      "    from: ./part3/starter_set/\n",
      "    range: [0, 114)\n",
      "load dataset done\n",
      "load test_dev dataset start\n",
      "    from: ./part3/starter_set/\n",
      "    range: [0, 114)\n",
      "load dataset done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DataLoaders.\n",
    "\"\"\"\n",
    "# TODO change data_range to include all train/evaluation/test data.\n",
    "# TODO adjust batch_size.\n",
    "train_data = FacadeDataset(\n",
    "    flag='train',\n",
    "    data_range=(0,20),\n",
    "    onehot=False,\n",
    ")\n",
    "train_loader = DataLoader(train_data, batch_size=1)\n",
    "\n",
    "test_data = FacadeDataset(\n",
    "    flag='test_dev',\n",
    "    data_range=(0,114),\n",
    "    onehot=False\n",
    ")\n",
    "test_loader = DataLoader(test_data, batch_size=1)\n",
    "\n",
    "ap_data = FacadeDataset(\n",
    "    flag='test_dev',\n",
    "    data_range=(0,114),\n",
    "    onehot=True\n",
    ")\n",
    "ap_loader = DataLoader(ap_data, batch_size=1)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210b3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN model.\n",
    "\"\"\"\n",
    "N_CLASS=5\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.n_class = N_CLASS\n",
    "        self.layers = nn.Sequential(\n",
    "            #########################################\n",
    "            ###        TODO: Add more layers      ###\n",
    "            #########################################\n",
    "            nn.Conv2d(3, self.n_class, 1, padding=0),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6202942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training\n",
      "-----------------Epoch = 1-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 60.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] loss: 1.704 elapsed time 0.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 20/20 [00:00<00:00, 80.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6431577146053313\n",
      "\n",
      "Finished Training, Testing on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 114/114 [00:01<00:00, 88.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6071406979309886\n",
      "\n",
      "Generating Unlabeled Result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████▎    | 104/114 [00:14<00:01,  7.58it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main function.\n",
    "\"\"\"\n",
    "# init model\n",
    "name = 'starter_net'\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss() #TODO decide loss\n",
    "optimizer = torch.optim.Adam(\n",
    "    net.parameters(),\n",
    "    1e-3,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "n_epochs = 1   #TODO decide epochs\n",
    "\n",
    "# train model\n",
    "print('\\nStart training')\n",
    "for epoch in range(n_epochs):\n",
    "    print('-----------------Epoch = %d-----------------' % (epoch+1))\n",
    "    train(\n",
    "        train_loader,\n",
    "        net,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        device,\n",
    "        epoch+1\n",
    "    )\n",
    "    # TODO create your evaluation set, load the evaluation set and test on evaluation set\n",
    "    evaluation_loader = train_loader\n",
    "    test(\n",
    "        evaluation_loader,\n",
    "        net,\n",
    "        criterion,\n",
    "        device\n",
    "    )\n",
    "\n",
    "# test trained model\n",
    "print('\\nFinished Training, Testing on test set')\n",
    "test(\n",
    "    test_loader,\n",
    "    net,\n",
    "    criterion,\n",
    "    device\n",
    ")\n",
    "print('\\nGenerating Unlabeled Result')\n",
    "result = get_result(\n",
    "    test_loader,\n",
    "    net,\n",
    "    device,\n",
    "    folder='./part3/output_test'\n",
    ")\n",
    "\n",
    "# save trained model\n",
    "torch.save(\n",
    "    net.state_dict(),\n",
    "    './part3/models/model_{}.pth'.format(name)\n",
    ")\n",
    "\n",
    "# calculate average precision\n",
    "cal_AP(ap_loader, net, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf62b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
